{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a933ecd-5d4c-461c-bcd3-f46e08f6400d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  experiments  llama  llama_langchain  tartu-nlp-courses-qa\n"
     ]
    }
   ],
   "source": [
    "!ls /gpfs/space/projects/stud_ml_22/NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035e9ace-a01e-4d35-96be-019cbbd19e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_exploration.py  main.py  requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /gpfs/space/projects/stud_ml_22/NLP/llama_langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "805432c1-8cc5-42c2-8da6-3c95473976f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/space/home/dzvenymy/.conda/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, AutoModel\n",
    "from accelerate import Accelerator\n",
    "import time\n",
    "\n",
    "from pydantic import BaseModel, Extra, Field, root_validator\n",
    "from typing import Any, List, Optional, Dict, Sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f060a4-c67b-48a1-bc73-7f57353cfdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cecf3a8-2fff-4dc3-910f-6db44ccea08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_dir = '/gpfs/space/projects/stud_ml_22/NLP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96371d2e-ea5e-420a-85e8-453a228b9181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/en/latest/getting_started/getting_started.html\n",
    "# https://python.langchain.com/en/latest/use_cases/question_answering.html\n",
    "# https://python.langchain.com/en/latest/modules/indexes/getting_started.html\n",
    "# https://python.langchain.com/en/latest/use_cases/question_answering/semantic-search-over-chat.html\n",
    "\n",
    "from langchain.base_language import BaseLanguageModel\n",
    "from langchain.callbacks.manager import Callbacks\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.embeddings.base import Embeddings\n",
    "# from langchain.llms import OpenAI\n",
    "from langchain.schema import Generation\n",
    "from langchain.schema import PromptValue, LLMResult\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "# langchain.document_loaders.DataFrameLoader has a quite a limited functionality\n",
    "class DataFrameLoader(BaseLoader):\n",
    "    def __init__(self, data_frame: Any, page_content_columns: List[str]):\n",
    "        if not isinstance(data_frame, pd.DataFrame):\n",
    "            raise ValueError(\n",
    "                f\"Expected data_frame to be a pd.DataFrame, got {type(data_frame)}\"\n",
    "            )\n",
    "        self.data_frame = data_frame\n",
    "        self.page_content_columns = page_content_columns\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        result = []\n",
    "        for i, row in self.data_frame.iterrows():\n",
    "            text = \"\"\n",
    "            metadata = {}\n",
    "            for col in self.page_content_columns:\n",
    "                data = row[col]\n",
    "                if isinstance(data, list):\n",
    "                    text += \"\".join(data) + \"\\n\"\n",
    "                elif isinstance(data, str):\n",
    "                    text += data + \"\\n\"\n",
    "                else:\n",
    "                    print(f\"[IGNORED] [{i}] [{col}] {data}\")\n",
    "\n",
    "            metadata_temp = row.to_dict()\n",
    "            for col in self.page_content_columns:\n",
    "                metadata_temp.pop(col)\n",
    "            # Metadata is a dict where a value can only be str, int, or float. Delete other types.\n",
    "            for key, value in metadata_temp.items():\n",
    "                if isinstance(value, (str, int, float)):\n",
    "                    metadata[key] = value\n",
    "\n",
    "            result.append(Document(page_content=text, metadata=metadata))\n",
    "        return result\n",
    "\n",
    "\n",
    "# class MyLanguageModel(BaseLanguageModel):\n",
    "#     def generate_prompt(self, prompts: List[PromptValue], stop: Optional[List[str]] = None,\n",
    "#                         callbacks: Callbacks = None) -> LLMResult:\n",
    "#         generation = Generation(text=\"Hello World!\")\n",
    "#         result = LLMResult(generations=[[generation]])\n",
    "#         return result\n",
    "\n",
    "#     async def agenerate_prompt(self, prompts: List[PromptValue], stop: Optional[List[str]] = None,\n",
    "#                                callbacks: Callbacks = None) -> LLMResult:\n",
    "#         pass  # \"whatever dude\"\n",
    "\n",
    "\n",
    "# # NOTE: the OpenAIEmbeddings embeddings have the dimensionality of 1536\n",
    "# class MyEmbeddings(Embeddings):\n",
    "#     def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "#         return [[1.0] * 1536, [2.0] * 1536]\n",
    "\n",
    "#     def embed_query(self, text: str) -> List[float]:\n",
    "#         return [1.0] * 1536\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "775d3f22-b482-476a-bf6a-fd9a43292e81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model(encoder_only = False):\n",
    "        PATH_TO_CONVERTED_WEIGHTS = os.path.join(\n",
    "            shared_dir, \"llama/7B_Vicuna_added/\")\n",
    "\n",
    "        device = torch.device(\n",
    "            \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "        config = AutoConfig.from_pretrained(PATH_TO_CONVERTED_WEIGHTS)\n",
    "        config.max_position_embeddings = 1024\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            PATH_TO_CONVERTED_WEIGHTS,\n",
    "            config=config,\n",
    "            trust_remote_code=True,\n",
    "            # use_cache=not args.no_gradient_checkpointing,\n",
    "            load_in_8bit=True,\n",
    "            device_map={\"\": Accelerator().process_index},\n",
    "            # device_map=\"auto\"\n",
    "        )\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da61bb46-b496-4482-8439-682aa8302ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import BaseMessage, LLMResult, PromptValue, get_buffer_string\n",
    "\n",
    "class LlamaWrapperModel(BaseLanguageModel):\n",
    "    model: Any\n",
    "    \n",
    "    @root_validator()\n",
    "    def validate_environment(cls, values: Dict) -> Dict:\n",
    "        values['model'] = get_model()\n",
    "        return values\n",
    "    \n",
    "    def predict(self, text: str, *, stop: Optional[Sequence[str]] = None) -> str:\n",
    "        pass\n",
    "    \n",
    "    def predict_messages(\n",
    "        self, messages: List[BaseMessage], *, stop: Optional[Sequence[str]] = None\n",
    "    ) -> BaseMessage:\n",
    "        pass\n",
    "\n",
    "    def generate_prompt(self, prompts: List[PromptValue], stop: Optional[List[str]] = None,\n",
    "                        callbacks: Callbacks = None) -> LLMResult:\n",
    "\n",
    "        # model = get_model()\n",
    "        PATH_TO_CONVERTED_TOKENIZER = os.path.join(\n",
    "            shared_dir, \"llama/7B_converted/\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(PATH_TO_CONVERTED_TOKENIZER)\n",
    "              \n",
    "        with torch.no_grad():\n",
    "            prompt = prompts[0].text\n",
    "            \n",
    "            print(\"Tokenizing...\")\n",
    "            s = time.time()\n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "            e1 = time.time()\n",
    "            print(\"Time to tokenize: \", time.strftime(\n",
    "                '%H:%M:%S', time.gmtime(e1 - s)))\n",
    "            \n",
    "            print(\"Generating...\")\n",
    "            generate_ids = self.model.generate(input_ids=inputs.input_ids.to(\n",
    "                device), max_length=5000)  # max_length = max_new_tokens + prompt_length\n",
    "            e2 = time.time()\n",
    "            print(\"Time to generate: \", time.strftime(\n",
    "                '%H:%M:%S', time.gmtime(e2 - e1)))\n",
    "            \n",
    "            print(\"Decoding...\")\n",
    "            text_result = tokenizer.batch_decode(\n",
    "                generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "            e3 = time.time()\n",
    "            print(\"Time to decode: \", time.strftime(\n",
    "                '%H:%M:%S', time.gmtime(e3 - e2)))\n",
    "\n",
    "        generation = Generation(text=text_result)\n",
    "        result = LLMResult(generations=[[generation]])\n",
    "        return result\n",
    "\n",
    "    async def agenerate_prompt(self, prompts: List[PromptValue], stop: Optional[List[str]] = None,\n",
    "                               callbacks: Callbacks = None) -> LLMResult:\n",
    "        pass  # \"whatever dude\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fe38752-36ad-4250-a687-620573c315dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: the OpenAIEmbeddings embeddings have the dimensionality of 1536\n",
    "\n",
    "device = torch.device('cuda')\n",
    "class DistilbertEmbeddings(Embeddings):\n",
    "   \n",
    "    def __init__(self):       \n",
    "        self.model = AutoModel.from_pretrained('distilbert-base-uncased').to(device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "       \n",
    "\n",
    "        # return values\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        # tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        # model = AutoModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "        # Tokenize the messages and generate embeddings\n",
    "        tokenized = [self.tokenizer.encode(text, add_special_tokens=True, max_length=512, truncation=True) for text in texts]\n",
    "        padded = np.array([i + [0]*(512-len(i)) for i in tokenized])\n",
    "       \n",
    "        input_ids = torch.tensor(padded)\n",
    "        embds = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(input_ids)-32, 32):\n",
    "                batch = input_ids[i:i+32].to(device)\n",
    "                last_hidden_states = self.model(batch)[0][:,0,:].cpu().numpy().tolist()\n",
    "                embds.extend(last_hidden_states)\n",
    "            last_batch = input_ids[(len(input_ids) // 32) * 32:].to(device)\n",
    "            last_hidden_states = self.model(last_batch)[0][:,0,:].cpu().numpy().tolist()\n",
    "            embds.extend(last_hidden_states)\n",
    "            \n",
    "        return embds\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        # tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        # model = AutoModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "        # Tokenize the messages and generate embeddings\n",
    "        tokenized = self.tokenizer.encode(text, add_special_tokens=True, max_length=512, truncation=True)\n",
    "        padded = np.array([tokenized+ [0]*(512-len(tokenized))])\n",
    "        input_ids = torch.tensor(padded)\n",
    "        with torch.no_grad():\n",
    "            last_hidden_states = self.model(input_ids.to(device))[0][:,0,:].cpu().numpy()\n",
    "        \n",
    "        return last_hidden_states[0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07479bb1-d597-4159-b53e-a60b8d191a65",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b81fe05e-37c0-4e67-aeae-9802845e57cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>code</th>\n",
       "      <th>parent_uuid</th>\n",
       "      <th>parent_code</th>\n",
       "      <th>parent_credits</th>\n",
       "      <th>title_en</th>\n",
       "      <th>general_input_languages</th>\n",
       "      <th>general_structural_unit_shares</th>\n",
       "      <th>general_year.en</th>\n",
       "      <th>general_type.code</th>\n",
       "      <th>...</th>\n",
       "      <th>resources_mandatory_materials</th>\n",
       "      <th>resources_recommended_materials</th>\n",
       "      <th>resources_learning_environments</th>\n",
       "      <th>participants_lecturers</th>\n",
       "      <th>participants_assistants</th>\n",
       "      <th>schedule_entries</th>\n",
       "      <th>schedule_weeks.et</th>\n",
       "      <th>registration_info_min_students</th>\n",
       "      <th>registration_info_max_students</th>\n",
       "      <th>registration_info_audience.en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a198ed66-1fb5-4f7e-ee43-7fbbf5c09aca</td>\n",
       "      <td>sv-2023-spring-openuniv</td>\n",
       "      <td>b99c0bb1-efd4-9b0a-857a-3dc7114e5c19</td>\n",
       "      <td>OIEO.06.046</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Private International Law</td>\n",
       "      <td>[{'language_code': 'et', 'language_name': 'Est...</td>\n",
       "      <td>[{'code': 'SVOI04', 'name': 'Department of Pri...</td>\n",
       "      <td>2023/2024</td>\n",
       "      <td>regular</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'person_uuid': 'd7a3f19b-d7c7-fbe5-b41b-e5e3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'course_week': 1, 'work_type': {'code': 'lec...</td>\n",
       "      <td>Nädalad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6ee943ab-a839-a937-76c0-2e0e4daedb8b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76162416-d608-f48f-ec5d-5c40ce9b320d</td>\n",
       "      <td>FLFI.00.016</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Doctoral Seminar</td>\n",
       "      <td>[{'language_code': 'et', 'language_name': 'Est...</td>\n",
       "      <td>[{'code': 'HVFI01', 'name': 'Department of Phi...</td>\n",
       "      <td>2023/2024</td>\n",
       "      <td>regular</td>\n",
       "      <td>...</td>\n",
       "      <td>Presentations.</td>\n",
       "      <td>Ask the supervisor.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'person_uuid': '4b6a00ae-35fd-a00e-d38e-0e2f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'work_type': {'code': 'colloquium', 'et': 'k...</td>\n",
       "      <td>24-40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7fc4f6cf-f011-91e8-4c42-abbd782a4a2a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31c327d5-2b61-c764-b418-bda22c577265</td>\n",
       "      <td>SVNC.00.179</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pedagogical Practicum</td>\n",
       "      <td>[{'language_code': 'et', 'language_name': 'Est...</td>\n",
       "      <td>[{'code': 'SVNC', 'name': 'Narva College', 'co...</td>\n",
       "      <td>2023/2024</td>\n",
       "      <td>practice</td>\n",
       "      <td>...</td>\n",
       "      <td>Põhikooli- ja gümnaasiumi Riiklik õppekava htt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'person_uuid': 'e664d700-4a63-b159-794e-d0be...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'work_type': {'code': 'practice', 'et': 'pra...</td>\n",
       "      <td>24-43</td>\n",
       "      <td>15.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d72f2ef7-d264-eceb-b759-a9a66cc27593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0e7d0b5d-83ea-f260-7e09-c3d59ea9c250</td>\n",
       "      <td>KKSB.05.092</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Practice in the Work Environment</td>\n",
       "      <td>[{'language_code': 'et', 'language_name': 'Est...</td>\n",
       "      <td>[{'code': 'MVSF', 'name': 'Institute of Sport ...</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>regular</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'person_uuid': '1ff846ac-79c1-ef64-3910-5131...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'time': '2023-06-20', 'work_type': {'code': ...</td>\n",
       "      <td>40-52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2a69334b-ebec-b332-d5f2-984869620c04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f465e112-e552-a3d1-5fa6-e26e661b288b</td>\n",
       "      <td>MTAT.03.242</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Bioinformatics Seminar</td>\n",
       "      <td>[{'language_code': 'et', 'language_name': 'Est...</td>\n",
       "      <td>[{'code': 'LTAT02', 'name': 'Chair of Data Sci...</td>\n",
       "      <td>2023/2024</td>\n",
       "      <td>regular</td>\n",
       "      <td>...</td>\n",
       "      <td>The readings for every topic could be found on...</td>\n",
       "      <td>The readings for every topic could be found on...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'person_uuid': '643ca845-067b-f270-23fd-dafe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'work_type': {'code': 'seminar', 'et': 'semi...</td>\n",
       "      <td>24.-39. õppenädalal</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   uuid                     code  \\\n",
       "0  a198ed66-1fb5-4f7e-ee43-7fbbf5c09aca  sv-2023-spring-openuniv   \n",
       "1  6ee943ab-a839-a937-76c0-2e0e4daedb8b                      NaN   \n",
       "2  7fc4f6cf-f011-91e8-4c42-abbd782a4a2a                      NaN   \n",
       "3  d72f2ef7-d264-eceb-b759-a9a66cc27593                      NaN   \n",
       "4  2a69334b-ebec-b332-d5f2-984869620c04                      NaN   \n",
       "\n",
       "                            parent_uuid  parent_code  parent_credits  \\\n",
       "0  b99c0bb1-efd4-9b0a-857a-3dc7114e5c19  OIEO.06.046             6.0   \n",
       "1  76162416-d608-f48f-ec5d-5c40ce9b320d  FLFI.00.016            15.0   \n",
       "2  31c327d5-2b61-c764-b418-bda22c577265  SVNC.00.179             4.0   \n",
       "3  0e7d0b5d-83ea-f260-7e09-c3d59ea9c250  KKSB.05.092             3.0   \n",
       "4  f465e112-e552-a3d1-5fa6-e26e661b288b  MTAT.03.242            12.0   \n",
       "\n",
       "                           title_en  \\\n",
       "0         Private International Law   \n",
       "1                  Doctoral Seminar   \n",
       "2             Pedagogical Practicum   \n",
       "3  Practice in the Work Environment   \n",
       "4            Bioinformatics Seminar   \n",
       "\n",
       "                             general_input_languages  \\\n",
       "0  [{'language_code': 'et', 'language_name': 'Est...   \n",
       "1  [{'language_code': 'et', 'language_name': 'Est...   \n",
       "2  [{'language_code': 'et', 'language_name': 'Est...   \n",
       "3  [{'language_code': 'et', 'language_name': 'Est...   \n",
       "4  [{'language_code': 'et', 'language_name': 'Est...   \n",
       "\n",
       "                      general_structural_unit_shares general_year.en  \\\n",
       "0  [{'code': 'SVOI04', 'name': 'Department of Pri...       2023/2024   \n",
       "1  [{'code': 'HVFI01', 'name': 'Department of Phi...       2023/2024   \n",
       "2  [{'code': 'SVNC', 'name': 'Narva College', 'co...       2023/2024   \n",
       "3  [{'code': 'MVSF', 'name': 'Institute of Sport ...       2022/2023   \n",
       "4  [{'code': 'LTAT02', 'name': 'Chair of Data Sci...       2023/2024   \n",
       "\n",
       "  general_type.code  ...                      resources_mandatory_materials  \\\n",
       "0           regular  ...                                                NaN   \n",
       "1           regular  ...                                     Presentations.   \n",
       "2          practice  ...  Põhikooli- ja gümnaasiumi Riiklik õppekava htt...   \n",
       "3           regular  ...                                                NaN   \n",
       "4           regular  ...  The readings for every topic could be found on...   \n",
       "\n",
       "                     resources_recommended_materials  \\\n",
       "0                                                NaN   \n",
       "1                                Ask the supervisor.   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  The readings for every topic could be found on...   \n",
       "\n",
       "   resources_learning_environments  \\\n",
       "0                              NaN   \n",
       "1                              NaN   \n",
       "2                              NaN   \n",
       "3                              NaN   \n",
       "4                              NaN   \n",
       "\n",
       "                              participants_lecturers participants_assistants  \\\n",
       "0  [{'person_uuid': 'd7a3f19b-d7c7-fbe5-b41b-e5e3...                     NaN   \n",
       "1  [{'person_uuid': '4b6a00ae-35fd-a00e-d38e-0e2f...                     NaN   \n",
       "2  [{'person_uuid': 'e664d700-4a63-b159-794e-d0be...                     NaN   \n",
       "3  [{'person_uuid': '1ff846ac-79c1-ef64-3910-5131...                     NaN   \n",
       "4  [{'person_uuid': '643ca845-067b-f270-23fd-dafe...                     NaN   \n",
       "\n",
       "                                    schedule_entries    schedule_weeks.et  \\\n",
       "0  [{'course_week': 1, 'work_type': {'code': 'lec...              Nädalad   \n",
       "1  [{'work_type': {'code': 'colloquium', 'et': 'k...                24-40   \n",
       "2  [{'work_type': {'code': 'practice', 'et': 'pra...                24-43   \n",
       "3  [{'time': '2023-06-20', 'work_type': {'code': ...                40-52   \n",
       "4  [{'work_type': {'code': 'seminar', 'et': 'semi...  24.-39. õppenädalal   \n",
       "\n",
       "   registration_info_min_students  registration_info_max_students  \\\n",
       "0                             1.0                            60.0   \n",
       "1                             1.0                             NaN   \n",
       "2                            15.0                            46.0   \n",
       "3                             1.0                            80.0   \n",
       "4                             5.0                             NaN   \n",
       "\n",
       "   registration_info_audience.en  \n",
       "0                            NaN  \n",
       "1                            NaN  \n",
       "2                            NaN  \n",
       "3                            NaN  \n",
       "4                            NaN  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(f'{shared_dir}/data/course_info.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33b18015-4ffe-4d18-9361-92151a29edea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>all_course_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The name of the course is Private Internationa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The name of the course is Doctoral Seminar. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The name of the course is Pedagogical Practicu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The name of the course is Practice in the Work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The name of the course is Bioinformatics Semin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                    all_course_info\n",
       "0           0  The name of the course is Private Internationa...\n",
       "1           1  The name of the course is Doctoral Seminar. Th...\n",
       "2           2  The name of the course is Pedagogical Practicu...\n",
       "3           3  The name of the course is Practice in the Work...\n",
       "4           4  The name of the course is Bioinformatics Semin..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{shared_dir}/data/courses_info_all.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59f1fea4-1f66-4a7a-b1d0-d8613892d87a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/space/projects/stud_ml_22/NLP/data/chroma\n"
     ]
    }
   ],
   "source": [
    "print(f\"{shared_dir}/data/chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10b69336-8f27-4782-b898-77633dcd853c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "loader = DataFrameLoader(df, [\"all_course_info\"])\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "embeddings = DistilbertEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "880c83fd-09bc-4f44-a29e-ae3f3fad0a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will create the chroma embedding database!!!\n",
    "documents = loader.load()\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39653a10-3a79-47d2-bf60-192747d6e807",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: /gpfs/space/projects/stud_ml_22/NLP/data/chroma_distilbert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "db = Chroma.from_documents(texts, embeddings, persist_directory=f\"{shared_dir}/data/chroma_distilbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25129f53-87d5-486f-a244-4c54553052fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /gpfs/space/home/dzvenymy/.conda/envs/nlp/lib/python3.10/site-packages/bitsandbytes-0.38.1-py3.10.egg/bitsandbytes/libbitsandbytes_cuda114_nocublaslt.so\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.0\n",
      "CUDA SETUP: Detected CUDA version 114\n",
      "CUDA SETUP: Loading binary /gpfs/space/home/dzvenymy/.conda/envs/nlp/lib/python3.10/site-packages/bitsandbytes-0.38.1-py3.10.egg/bitsandbytes/libbitsandbytes_cuda114_nocublaslt.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/space/home/dzvenymy/.conda/envs/nlp/lib/python3.10/site-packages/bitsandbytes-0.38.1-py3.10.egg/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n",
      "  warn(msg)\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.91s/it]\n"
     ]
    }
   ],
   "source": [
    "llm = LlamaWrapperModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b229b64f-4736-4eab-a559-06de223ad241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CANNOT LOAD FROM DISK BECAUSE OF EMBD DIM INIT BUG\n",
    "# db = Chroma(persist_directory=f\"{shared_dir}/data/chroma\", embedding_function=embeddings)  # load from disk \n",
    "retriever = db.as_retriever()\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ea162ed-69d0-4a12-961b-1cd982da8291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "Time to tokenize:  00:00:00\n",
      "Generating...\n",
      "Time to generate:  00:00:03\n",
      "Decoding...\n",
      "Time to decode:  00:00:00\n",
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "The name of the course is Advanced Seminar in Ancient History. The purpose of the course is  ' ' ' Language of instruction is Estonian. The course is offered by Department of General History. The course is taught in 2023/2024 years. The course is a Regular course.    Number of seminar hours is 30.    Number of credits is 12.0. The course lecturers are: Mait Kõiv.\n",
      "\n",
      "Question: What is the language of instruction for Advanced Seminar in Ancient History?\n",
      "Helpful Answer: The language of instruction for Advanced Seminar in Ancient is Estonian.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the language of instruction for Advanced Seminar in Ancient History?\"\n",
    "print(qa.run(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de60fdd1-940c-456a-829b-b36500eb8280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
